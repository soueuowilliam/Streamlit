# rag_core.py
import os
from dotenv import load_dotenv

from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader

from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

def carregar_documentos(caminho):
    documentos = []

    if os.path.isdir(caminho):
        for arquivo in os.listdir(caminho):
            arquivo_norm = arquivo.strip().lower()
            caminho_arquivo = os.path.join(caminho, arquivo)

            if not os.path.isfile(caminho_arquivo):
                continue

            try:
                if arquivo_norm.endswith('.pdf'):
                    documentos.extend(PyPDFLoader(caminho_arquivo).load())
                elif arquivo_norm.endswith('.doc'):
                    documentos.extend(Docx2txtLoader(caminho_arquivo).load())
                else:
                    continue
                    
            except Exception as e:
                print(f'Falha ao ler {arquivo}: {e}')

    if not documentos:
        raise RuntimeError('Nenhum documento encontrado.')

    embeddings = GoogleGenerativeAIEmbeddings(
        model="text-embedding-004",
        google_api_key=api_key
    )

    splitter = RecursiveCharacterTextSplitter( chunk_size = 500, chunk_overlap = 100 )
    chunks = splitter.split_documents(documentos)

    retriever = FAISS.from_documents(chunks, embeddings).as_retriever(search_kwargs = {"k": 3})
    
    return retriever

def formatar_contexto(docs):
    textos = []
    for doc in docs:
        arquivo = os.path.basename(doc.metadata.get("source", "N/A"))
        pagina = doc.metadata.get("page")
        pagina_txt = f"P√°gina {pagina + 1}" if pagina is not None else "P√°gina n√£o aplic√°vel"
        textos.append(f"üìÑ {arquivo} | {pagina_txt}\n{doc.page_content}")
    return "\n\n".join(textos)

_chain = None

def inicializacao(pasta:str):
    global _chain
    retriever = carregar_documentos(pasta)

    prompt = ChatPromptTemplate.from_messages([
        (
            "system",
            """
Voc√™ √© um Assistente de An√°lise Documental especializado em RAG. Sua fun√ß√£o √© ler os fragmentos de documentos fornecidos, localizar a "PALAVRA_ALVO" e explicar o seu contexto.

INSTRU√á√ïES PRINCIPAIS:
1. Localize as ocorr√™ncias da PALAVRA_ALVO no texto fornecido.
2. A busca deve ser em CASE-INSENSITIVE (ignore mai√∫sculas/min√∫sculas).
3. Para cada ocorr√™ncia relevante, voc√™ deve extrair o trecho exato e gerar uma breve explica√ß√£o sobre o que aquele trecho diz a respeito da palavra.

REGRAS DE SEGURAN√áA (GUARDRAILS):
- Utilize SOMENTE as informa√ß√µes presentes no contexto fornecido. N√£o use conhecimento externo.
- Se a palavra aparecer m√∫ltiplas vezes no mesmo par√°grafo, agrupe em uma √∫nica ocorr√™ncia.
- Se a PALAVRA_ALVO n√£o for encontrada ou n√£o houver contexto suficiente para explicar, responda EXATAMENTE:
  "A palavra 'PALAVRA_ALVO' n√£o foi encontrada ou n√£o possui contexto relevante nos documentos."

FORMATO DE RESPOSTA (Obrigat√≥rio):
Para cada ocorr√™ncia encontrada, siga estritamente este padr√£o:

---
*Documento:* <nome_do_arquivo_se_disponivel_nos_metadados>
*P√°gina:* <numero_da_pagina_se_disponivel>
*Trecho Original:* "<cite exatamente a frase ou par√°grafo onde a palavra aparece>"
*Explica√ß√£o:* <Escreva aqui uma breve explica√ß√£o (2 a 3 linhas) resumindo o que este trecho diz sobre a PALAVRA_ALVO>
---
    
    Contexto:
    {contexto}
        """
        ),
        ("human", "{pergunta}")
    ])

    
    modelo = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.5, google_api_key=api_key)
    _chain = (
        {
        'contexto': RunnablePassthrough() | retriever | formatar_contexto ,
        'pergunta': RunnablePassthrough()
        } | prompt | modelo | StrOutputParser()
    )


def responder(pergunta: str) -> str: 
    if _chain is None:
        raise RuntimeError('Modelo n√£o inicializado')
    return _chain.invoke(pergunta)





















