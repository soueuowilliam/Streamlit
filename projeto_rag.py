# rag_core.py
import os
from dotenv import load_dotenv

from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader

from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

def carregar_documentos(caminho):
    documentos = []

    if os.path.isdir(caminho):
        for arquivo in os.listdir(caminho):
            arquivo_norm = arquivo.strip().lower()
            caminho_arquivo = os.path.join(caminho, arquivo)

            if not os.path.isfile(caminho_arquivo):
                continue

            try:
                if arquivo_norm.endswith('.pdf'):
                    documentos.extend(PyPDFLoader(caminho_arquivo).load())
                elif arquivo_norm.endswith('.doc'):
                    documentos.extend(Docx2txtLoader(caminho_arquivo).load())
                else:
                    continue
                    
            except Exception as e:
                print(f'Falha ao ler {arquivo}: {e}')

    if not documentos:
        raise RuntimeError('Nenhum documento encontrado.')

    embeddings = GoogleGenerativeAIEmbeddings(
        model="text-embedding-004",
        google_api_key=api_key
    )

    splitter = RecursiveCharacterTextSplitter( chunk_size = 500, chunk_overlap = 100 )
    chunks = splitter.split_documents(documentos)

    retriever = FAISS.from_documents(chunks, embeddings).as_retriever(search_kwargs = {"k": 3})
    
    return retriever

def formatar_contexto(docs):
    textos = []
    for doc in docs:
        arquivo = os.path.basename(doc.metadata.get("source", "N/A"))
        pagina = doc.metadata.get("page")
        pagina_txt = f"P√°gina {pagina + 1}" if pagina is not None else "P√°gina n√£o aplic√°vel"
        textos.append(f"üìÑ {arquivo} | {pagina_txt}\n{doc.page_content}")
    return "\n\n".join(textos)

_chain = None

def inicializacao(pasta:str):
    global _chain
    retriever = carregar_documentos(pasta)

    prompt = ChatPromptTemplate.from_messages([
        (
            "system",
            """
Voc√™ √© um Assistente de Extra√ß√£o e An√°lise Documental. Sua tarefa √© localizar a "PALAVRA_ALVO" dentro do "CONTEXTO", extrair o trecho exato e explicar o significado naquele ponto.

### INSTRU√á√ïES DE BUSCA E AN√ÅLISE:
1.  *Busca Literal:* Localize onde a PALAVRA_ALVO aparece no texto abaixo. Ignore mai√∫sculas/min√∫sculas.
2.  *Contexto:* Use APENAS o texto fornecido na se√ß√£o "CONTEXTO". N√£o invente informa√ß√µes.
3.  *Explica√ß√£o:* Para cada ocorr√™ncia, leia o par√°grafo ao redor e explique em 1 frase o que est√° sendo dito sobre a palavra.

### FORMATO DE RESPOSTA (Markdown Obrigat√≥rio):
Voc√™ deve responder usando estritamente a formata√ß√£o abaixo para que o sistema exiba corretamente. Use divisores (---) entre ocorr√™ncias diferentes.

Se encontrar a palavra:
---
*üìÑ Documento:* [Nome do Arquivo/Metadado]\n
*üìç P√°gina:* [N√∫mero]\n
*üí¨ Trecho Original:*\n
> "...[copie o trecho exato onde a palavra aparece]..."

>> *üí° Explica√ß√£o:* [Sua explica√ß√£o concisa do contexto aqui]
---

Se N√ÉO encontrar a palavra:
> ‚ö†Ô∏è A palavra *'PALAVRA_ALVO'* n√£o foi localizada nos documentos fornecidos.

    Contexto:
    {contexto}
        """
        ),
        ("human", "{pergunta}")
    ])

    
    modelo = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.5, google_api_key=api_key)
    _chain = (
        {
        'contexto': RunnablePassthrough() | retriever | formatar_contexto ,
        'pergunta': RunnablePassthrough()
        } | prompt | modelo | StrOutputParser()
    )


def responder(pergunta: str) -> str: 
    if _chain is None:
        raise RuntimeError('Modelo n√£o inicializado')
    return _chain.invoke(pergunta)






















